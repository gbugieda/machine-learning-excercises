{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "black-renaissance",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "Fill in your name and the link to this file on your github.\n",
    "\n",
    "* Name: Gia Bugieda  \n",
    "* Link to github URL: https://github.com/gbugieda/machine-learning-excercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "enormous-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-confidence",
   "metadata": {},
   "source": [
    "# ML: Linear Regression\n",
    "\n",
    "So this starts with linear regression. If you want a deeper dive than what I cover in class, you can refer to [this page](https://realpython.com/linear-regression-in-python/)\n",
    "\n",
    "The exercises come from this workbook, which has somewhat helpful explanations too: https://csmastersuh.github.io/data_analysis_with_python_2020/linear_regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-johnston",
   "metadata": {},
   "source": [
    "# Exercise 10: Linear Regression\n",
    "\n",
    "You'll need to make up some data for this. Don't spend too much time on this one, it's less interesting compared to the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "automotive-layer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope:  1.923542112235756\n",
      "Intercept:  1.5113274454722578\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=20\n",
    "# Linearly increasing x values\n",
    "x = np.linspace(0, 10, n)\n",
    "# Wonky line of points\n",
    "y = x*2 + 1 + 1*np.random.randn(n)\n",
    "#display(x, y)\n",
    "#plt.scatter(x, y)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# Do actual linear regression here\n",
    "def fit_line(x,y):\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    model.fit(x[:,np.newaxis], y)\n",
    "    return (model.coef_[0],model.intercept_)\n",
    "\n",
    "\n",
    "def main():\n",
    "    slope,intercept = fit_line(x,y)\n",
    "    print(\"Slope: \", slope)\n",
    "    print(\"Intercept: \", intercept)\n",
    "    xfit=np.linspace(0,10,100)\n",
    "    yfit= slope*xfit + intercept # y = mx+b\n",
    "    plt.scatter(x,y) #showing original data points\n",
    "    plt.plot(xfit,yfit) #plotting my line\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-grenada",
   "metadata": {},
   "source": [
    "# Exercise 11: Mystery Data\n",
    "\n",
    "This one is far more interesting. You can download the file from [here](https://raw.githubusercontent.com/AnkS4/hy-data-analysis-with-python-2020/master/part05-e11_mystery_data/src/mystery_data.tsv). Make sure it gets the right filename!\n",
    "\n",
    "You don't need to define any functions, as they demand, although you might find that helpful to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "foster-purchase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of X1 is 2.7586066857399567\n",
      "Coefficient of X2 is -2.017739903421609\n",
      "Coefficient of X3 is 6.341012911933917\n",
      "Coefficient of X4 is 0.37382551354719074\n",
      "Coefficient of X5 is -19.722787617622036\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def mystery_data():\n",
    "    coeff_arr = []\n",
    "    cols = ['X1', 'X2','X3', 'X4', 'X5']\n",
    "    #read in file\n",
    "    df = pd.read_csv(\"mystery_data.tsv\", sep='\\t')\n",
    "    for num in range(0,5):\n",
    "        model = LinearRegression(fit_intercept=True)\n",
    "        model.fit(df[cols[num]][:,np.newaxis], df['Y'])\n",
    "        coeff_arr.append(model.coef_[0])\n",
    "    \n",
    "    return coeff_arr\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    arr = mystery_data();\n",
    "    print(\"Coefficient of X1 is\",arr[0])\n",
    "    print(\"Coefficient of X2 is\",arr[1])\n",
    "    print(\"Coefficient of X3 is\",arr[2])\n",
    "    print(\"Coefficient of X4 is\",arr[3])\n",
    "    print(\"Coefficient of X5 is\",arr[4])\n",
    "    \n",
    "main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-thought",
   "metadata": {},
   "source": [
    "## Exercise 12: Coefficient of Determination\n",
    "\n",
    "Read over this entire problem, parts 1 and 2.\n",
    "\n",
    "This reuses the same `mystery_data.tsv` file as before.\n",
    "\n",
    "Again, you do not need to define their function. Just calculate the R2 scores and print them, as they direct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "maritime-blond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2-score with feature(s) X: 1.0\n",
      "R2-score with feature(s) X1: 0.01691827260276868\n",
      "R2-score with feature(s) X2: 0.008964585308688933\n",
      "R2-score with feature(s) X3: 0.08785404530656282\n",
      "R2-score with feature(s) X4: 0.0003023708825460325\n",
      "R2-score with feature(s) X5: 0.8679744020096123\n"
     ]
    }
   ],
   "source": [
    "#fit data using linear regression\n",
    "\n",
    "r2_arr = []\n",
    "cols = ['X1', 'X2','X3', 'X4', 'X5']\n",
    "#read in file\n",
    "df = pd.read_csv(\"mystery_data.tsv\", sep='\\t')\n",
    "model.fit(df.iloc[:,0:5],df['Y'])\n",
    "x = model.score(df.iloc[:,0:5],df['Y'])\n",
    "r2_arr.append(x)\n",
    "for num in range(0,5):\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    model.fit(df[cols[num]][:,np.newaxis], df['Y'])\n",
    "    r2_arr.append(model.score(df[cols[num]][:,np.newaxis], df['Y']))\n",
    "\n",
    "\n",
    "print(\"R2-score with feature(s) X:\", r2_arr[0])\n",
    "print(\"R2-score with feature(s) X1:\", r2_arr[1])\n",
    "print(\"R2-score with feature(s) X2:\", r2_arr[2])\n",
    "print(\"R2-score with feature(s) X3:\", r2_arr[3])\n",
    "print(\"R2-score with feature(s) X4:\", r2_arr[4])\n",
    "print(\"R2-score with feature(s) X5:\", r2_arr[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-island",
   "metadata": {},
   "source": [
    "## Exercise 13: Cycling Weather\n",
    "\n",
    "I've already prepared the data that they require for this assignment. You can download it [here](https://gist.githubusercontent.com/acbart/466174a04e9a2505c4c25f91fc6dd4f6/raw/726865070677ec7dede17a08095624e0ea35e7cd/biking.csv).\n",
    "\n",
    "The first column is the index, you can safely ignore it. The next 7 columns are straightforward. The last few columns are locations in Finland that have measuring stations. I recommend using `Baana` as they say in the instructions for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "confident-carnival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring station: Baana\n",
      "Regression coefficient for variable 'precipitation': -52.2\n",
      "Regression coefficient for variable 'snow depth':-32.9\n",
      "Regression coefficient for variable 'temperature':169.2\n",
      "Score:0.58\n"
     ]
    }
   ],
   "source": [
    "#read in file\n",
    "bike = pd.read_csv(\"biking.csv\")\n",
    "\n",
    "def cycling_weather_continues(station):\n",
    "    variables = bike[[\"Precipitation amount (mm)\", \"Snow depth (cm)\", \"Air temperature (degC)\"]]\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    model.fit(variables,bike[station])\n",
    "    score = model.score(variables,bike[station])\n",
    "    return (model.coef_, score)\n",
    "    \n",
    "\n",
    "def main():\n",
    "    station = \"Baana\"\n",
    "    coeff,sc = cycling_weather_continues(station)\n",
    "    print(f\"Measuring station:\", station)\n",
    "    print(f\"Regression coefficient for variable 'precipitation': {coeff[0]:.1f}\")\n",
    "    print(f\"Regression coefficient for variable 'snow depth':{coeff[1]:.1f}\")\n",
    "    print(f\"Regression coefficient for variable 'temperature':{coeff[2]:.1f}\")\n",
    "    print(f\"Score:{sc:.2f}\")\n",
    "    \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-triple",
   "metadata": {},
   "source": [
    "# ML Naive Bayes Classification\n",
    "\n",
    "This is the next section of the exercises, from: https://csmastersuh.github.io/data_analysis_with_python_2020/bayes.html\n",
    "\n",
    "In addition to the reading, I recommend this video: https://www.youtube.com/watch?v=CPqOCI0ahss\n",
    "\n",
    "\n",
    "## Exercise 1: Blob Classification\n",
    "\n",
    "(**OPTIONAL**) This one is very vague, and they're actually asking you to generate your own test data using the `make_blobs` function from `sklearn`'s `datasets` submodule. I've already started that work for you. But honestly if you want to skip it, I don't think it's a helpful starting question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sufficient-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is None\n",
      "array([[2.0, 2.0, 0.0, 2.5, None],\n",
      "       [2.0, 3.0, 1.0, 1.5, None],\n",
      "       [2.0, 2.0, 6.0, 3.5, None],\n",
      "       [2.0, 2.0, 3.0, 1.2, None],\n",
      "       [2.0, 4.0, 4.0, 2.7, None]], dtype=object)\n"
     ]
    }
   ],
   "source": [
    "def blob_classification(X, y):\n",
    "    # Put ML stuff here\n",
    "    pass\n",
    "\n",
    "# Create the training data and validation data\n",
    "X, y = datasets.make_blobs(100, 2, centers=2, random_state=2, cluster_std=2.5)\n",
    "# Run your ML predictions\n",
    "print(\"The accuracy score is\", blob_classification(X, y))\n",
    "# Run this on some new data\n",
    "a=np.array([[2, 2, 0, 2.5],\n",
    "            [2, 3, 1, 1.5],\n",
    "            [2, 2, 6, 3.5],\n",
    "            [2, 2, 3, 1.2],\n",
    "            [2, 4, 4, 2.7]])\n",
    "accuracies = []\n",
    "for row in a:\n",
    "    X,y = datasets.make_blobs(100, int(row[0]), centers=int(row[1]),\n",
    "                              random_state=int(row[2]), cluster_std=row[3])\n",
    "    accuracies.append(blob_classification(X, y))\n",
    "print(repr(np.hstack([a, np.array(accuracies)[:,np.newaxis]])))\n",
    "# The last column should be the categorizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-trinity",
   "metadata": {},
   "source": [
    "## Exercise 2: Plant Classification\n",
    "\n",
    "This is a much better question. The Iris dataset is a classic: https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "\n",
    "The wikipedia page gives an example of how to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "thrown-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "valued-childhood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plant_classification():\n",
    "    #load in dataset\n",
    "    iris = load_iris()\n",
    "    X = iris[\"data\"]\n",
    "    y = iris[\"target\"]\n",
    "    \n",
    "    #split data into training/testing\n",
    "    x_train, x_split, y_train, y_split = train_test_split(X,y, train_size= 0.80,random_state=0)\n",
    "    \n",
    "    #guassian naive bayes to fit training data\n",
    "    model = GaussianNB()\n",
    "    model.fit(x_train,y_train)\n",
    "    \n",
    "    #predict labels\n",
    "    labels_fitted = model.predict(x_split)\n",
    "    \n",
    "    return accuracy_score(labels_fitted,y_split)\n",
    "\n",
    "\n",
    "plant_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-gates",
   "metadata": {},
   "source": [
    "## Exercise 3: Word Classification\n",
    "\n",
    "(**Skip**)\n",
    "\n",
    "This one is too much. They give some of the data as an XML file. It's an interesting problem, and you can find the data (and solution) [here](https://github.com/AnkS4/hy-data-analysis-with-python-2020/tree/master/part06-e03_word_classification/src) if you want to tackle it, but I'm skipping it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-brisbane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faced-maine",
   "metadata": {},
   "source": [
    "## Exercise 4: Spam Detection\n",
    "\n",
    "Download [ham.txt.gz](https://github.com/AnkS4/hy-data-analysis-with-python-2020/raw/master/part06-e04_spam_detection/src/ham.txt.gz) and [spam.txt.gz](https://github.com/AnkS4/hy-data-analysis-with-python-2020/raw/master/part06-e04_spam_detection/src/spam.txt.gz).\n",
    "\n",
    "This one is much more interesting and reasonable. It requires processing some large text files, but that's actually the easiest part, as shown in the code below. The idea is that you have spam (bad emails) and ham (good emails), and you want to determine which is which. I've done similar email processing (detecting job ads for a conference) and I was impressed with how easily I could train a little data and get very good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "stunning-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dynamic-snapshot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spam emails loaded as strings: 500\n",
      "Number of ham emails loaded as strings: 2500\n",
      "accuracy score:  0.9613333333333334\n",
      "test sample size:  2250\n",
      "num misclassified points:  29\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "# Load the spam emails as strings in a list.\n",
    "with gzip.open('spam.txt.gz', 'rb') as spam_file:\n",
    "    spam = spam_file.readlines()\n",
    "print(\"Number of spam emails loaded as strings:\", len(spam))\n",
    "\n",
    "# Now do the same thing with the `ham.txt.gz`\n",
    "with gzip.open('ham.txt.gz', 'rb') as ham_file:\n",
    "    ham = ham_file.readlines()\n",
    "print(\"Number of ham emails loaded as strings:\", len(ham))\n",
    "\n",
    "# And then do the actual ML stuff\n",
    "emails = ham + spam\n",
    "\n",
    "vec = CountVectorizer()\n",
    "emails = vec.fit_transform(emails).toarray()\n",
    "labels = np.zeros(len(emails))\n",
    "labels[len(ham):] = 1\n",
    "\n",
    "x_train, x_split, y_train, y_split = train_test_split(emails,labels, train_size= 0.75,random_state=1)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train,y_train)\n",
    "    \n",
    "#predict labels\n",
    "labels_fitted = model.predict(x_split)\n",
    "    \n",
    "print(\"accuracy score: \", accuracy_score(labels_fitted,y_split))\n",
    "print(\"test sample size: \", len(x_train))\n",
    "print(\"num misclassified points: \", (labels_fitted != y_split).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-chapel",
   "metadata": {},
   "source": [
    "# ML Clustering\n",
    "\n",
    "This is the last section: https://csmastersuh.github.io/data_analysis_with_python_2020/clustering.html\n",
    "\n",
    "This section is one of the most interesting in my opinion. K-Means is a pretty straightforward tool, and is really worth learning how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-sustainability",
   "metadata": {},
   "source": [
    "## Exercise 5: Plant Clustering\n",
    "\n",
    "Same deal as before; use the IRIS dataset. Since this has so many parameters, it can be tricky to make a good visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-university",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eligible-surface",
   "metadata": {},
   "source": [
    "## Exercise 6: Non-convex Clusters\n",
    "\n",
    "The data for this question is [here](https://raw.githubusercontent.com/AnkS4/hy-data-analysis-with-python-2020/master/part06-e06_nonconvex_clusters/src/data.tsv).\n",
    "\n",
    "This one shows off a different clustering algorithm ([`DBSCAN`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)), which is \"Good for data which contains clusters of similar density\". I wasn't very familiar with DBSCAN, but it does seem much better than KMeans. It doesn't require you to figure out the number of clusters, and seems to be tricked less by unusual data. [This page](https://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html) was very helpful in breaking that difference down.\n",
    "\n",
    "The reference answer uses a `for` loop and `np.arange` to try `e` values from 0.05 to 0.2 in 0.05 increments, but I don't mind if you just manually try some different `e` values.\n",
    "\n",
    "Please do make a visualization with clusters colored, since I think that really highlights what we are doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-clearance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "joint-tenant",
   "metadata": {},
   "source": [
    "## Exercise 7: Binding Sites\n",
    "\n",
    "Download the [`data.seq` file](https://raw.githubusercontent.com/AnkS4/hy-data-analysis-with-python-2020/master/part06-e07_binding_sites/src/data.seq); note that it is just a plain textual data file, despite the fancy extension.\n",
    "\n",
    "They ask you to define `get_features_and_labels` to accept a filename, even though there's only one test file. Up to you if you want to hardcode the file path in or make it a flexible function.\n",
    "\n",
    "There are multiple parts here, and they ask you to compare the euclidean and hamming distance. I think it's worth thinking about - if you don't get what they mean, do ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "comparable-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The `find_permutation` function provided in the text, for your convenience\n",
    "def find_permutation(n_clusters, real_labels, labels):\n",
    "    permutation=[]\n",
    "    for i in range(n_clusters):\n",
    "        idx = labels == i\n",
    "        # Choose the most common label among data points in the cluster\n",
    "        new_label=scipy.stats.mode(real_labels[idx])[0][0]\n",
    "        permutation.append(new_label)\n",
    "    return permutation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
